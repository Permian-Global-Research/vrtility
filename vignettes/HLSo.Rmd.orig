---
title: "Harmonized Landsat Sentinel-2"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Harmonized Landsat Sentinel-2}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

The Harmonized Landsat Sentinel-2 (HLS) project is fantastic dataset offering
global, harmonized surface reflectance data from Landsat 8 and Sentinel-2
satellites. The combined measurement enables global observations of the land 
every 2â€“3 days at 30-meter (m) spatial resolution. The data has a high quality
cloud/shadow bitmask layer, enabling the creation of excellent cloud-free
composites. Further information on HLS can be found at the following links:

- https://hls.gsfc.nasa.gov/

- https://lpdaac.usgs.gov/products/hlsl30v002/

- https://github.com/nasa/HLS-Data-Resources?tab=readme-ov-file

Combining the Harmonized landsat and sentinel collections does require some
additional work because the two collections have different numbers of bands with 
different names. 

This Vignette outlines a workflow to combine the two collections into a single
median composite image that maintains all available bands.

You will need to have an Earthdata account to access the HLS data. You can
create an account at https://urs.earthdata.nasa.gov/users/new.


## Workflow setup

First we load the `vrtility` package and set up our multiprocessing daemons
using the `mirai` package. Using mirai daemons allows for the automated speed
up of several of the vrtility processing steps.

Next we define our area of interest, we do this using the `gdalraster` package
but you can as easily simply provide a numeric vector (length 4) with lon/lat 
coordinates ordered by xmin, ymin, xmax, ymax.

When working with any raster data it is often more convenient to use a projected 
coordinate system. The `bbox_to_projected` function provides a convenient way
to reproject a bounding box, either with a specific spatial reference system 
(SRS) or using a default SRS appropriate for the area of interest. The default 
SRS is an equal area projection centered around the centroid of the bounding 
box.

```{r setup}
library(vrtility)

mirai::daemons(10)

bbox <- gdalraster::bbox_from_wkt(
  wkt = wk::wkt("POINT (144.3 -7.6)"),
  extend_x = 0.17,
  extend_y = 0.125
)

te <- bbox_to_projected(bbox)
trs <- attr(te, "wkt")
```

Now we need to find the data. we need to query both the HLS Landsat and Sentinel-2
collections. The `hls_stac_query` function provides a convenient way to do this.
First we will query the HLS Landsat collection. Here we set a maximum cloud cover
of 35% and a date range of 2023-01-01 to 2023-12-31. we can see that of a total
of 70 images, only 6 had less than 35% cloud cover. 

```{r hlssl}
hlssl_stac <- hls_stac_query(
  bbox = bbox,
  start_date = "2023-01-01",
  end_date = "2023-12-31",
  max_cloud_cover = 35,
  collection = "HLSL30_2.0"
)
print(hlssl_stac)
```

And now we will query the HLS Sentinel-2 collection using the same parameters.
Again we can see that < 10% of images have less than 35% cloud cover. 


```{r hlsss}
hlsss_stac <- hls_stac_query(
  bbox = bbox,
  start_date = "2023-01-01",
  end_date = "2023-12-31",
  max_cloud_cover = 35,
  collection = "HLSS30_2.0"
)
print(hlsss_stac)
```

In order to download the data we need to set up our Earthdata credentials. The 
simplest way to do this is with the 
[earthdatalogin](https://boettiger-lab.github.io/earthdatalogin/) package. But, 
because we are using asynchronous mirai daemons, we need to set the credentials 
for all daemons.


```{r earthdata-creds}
mirai::everywhere(earthdatalogin::edl_netrc(
  username = Sys.getenv("EARTHDATA_USER"),
  password = Sys.getenv("EARTHDATA_PASSWORD")
))
```

Now we can begin forming the VRT pipeline. Here we "collect" all of the assets
from the STAC collections. This is essentially just a list of virtual rasters.
This can take a little time due to VRT validation -  however, GDAL caching 
makes re-accessing these remote files faster, for the subsequent parts of the
workflow.


```{r hls-collect}
hls_sl_col <- vrt_collect(hlssl_stac)
print(hls_sl_col)

hls_ss_col <- vrt_collect(hlsss_stac)
print(hls_ss_col)
```

The print method for vrt_collection objects gives us a high level overview of
the imagery we will download. Our collections contain images with two different
SRS. We can also see that the number of bands differs across the two 
collections.


Now we set the mask function required for the HLS data. The "Fmask" band is a 
true bitmask (unlike other datasets which may use ineger masks). Therefore
we must use the `build_bitmask` function to set the mask and can specify the
bits that we wish to set as nodata across all bands.

```{r hls-mask}
hls_sl_col_mask <- vrt_set_maskfun(
  hls_sl_col,
  mask_band = "Fmask",
  mask_values = c(0, 1, 2, 3),
  build_mask_pixfun = build_bitmask(),
  drop_mask_band = TRUE
)

hls_ss_col_mask <- vrt_set_maskfun(
  hls_ss_col,
  mask_band = "Fmask",
  mask_values = c(0, 1, 2, 3),
  build_mask_pixfun = build_bitmask(),
  drop_mask_band = TRUE
)

# let's check out a vrt and inspect the mask function that we used.
print(hls_sl_col_mask, maskfun = TRUE)
```


Now we need to align these data so that we can composite all the imagery in one 
go. We can do this by simply adding nodata bands where required. In the case 
of the HLS Landsat collection, we also need to move the position of the cirrus
band to match that of the HLS Sentinel-2 collection.

Similarly, with HLS Sentinel-2, we need to add the thermal bands that are 
absent, but critically, note that we need to specify the scale value for these
bands. If this isn't provided then the scale from the first band is used 
(which in this case is 0.0001) or if there is no scale, it is ignored. Automating
this is tricky but if you miss an appropriate scale, you will see warnings 
when you then use `vrt_stack`.


```{r band-align-hls}
hls_ls_align <- vrt_set_band_names(
  hls_sl_col_mask,
  c("A", "B", "G", "R", "N2", "S1", "S2", "C", "T1", "T2")
) |>
  vrt_add_empty_band(after = 4, description = "RE1") |>
  vrt_add_empty_band(after = 5, description = "RE2") |>
  vrt_add_empty_band(after = 6, description = "RE3") |>
  vrt_add_empty_band(after = 7, description = "N") |>
  vrt_add_empty_band(after = 9, description = "WV") |>
  vrt_move_band(band_idx = 13, after = 10)



hls_ss_align <- vrt_set_band_names(
  hls_ss_col_mask,
  c("A", "B", "G", "R", "RE1", "RE2", "RE3", "N", "N2", "WV", "C", "S1", "S2")
) |>
  vrt_add_empty_band(after = 13, description = "T1", scale_value = 0.01) |>
  vrt_add_empty_band(after = 14, description = "T2", scale_value = 0.01)
```

Now we can combine the two collections into a single collection using the `c` 
method. This is a simple concatenation of the two collections.

```{r hls-merge}
hls_merge_coll <- c(
  hls_ls_align,
  hls_ss_align
)
```

Now we need to warp all vrt_blocks in the collection to the same spatial
reference system, extent and pixel size. This is particularly important in this
case because of the mutliple SRS in the collection. Also to make use of the
fastest `vrt_compute` engine, we need to ensure that all blocks are in the same
SRS with equal dimensions.

```{r hls-warp}
hls_warp <- vrt_warp(
  hls_merge_coll,
  t_srs = trs,
  te = te,
  tr = c(30, 30),
  resampling = "bilinear"
)
```

Now we can stack the warped vrt collection - this can be thought of as a virtual 
raster cube. Then, we can set a pixel function which defines how the mutliple
images for each band are summarised. Here we use the median_numpy pixel 
function to compute the cell-level median. 

```{r hls-stack}
hls_stack <- vrt_stack(hls_warp) |>
  vrt_set_pixelfun(pixfun = median_numpy())
```

Finally we compute all of this using vrt_compute. Note that we specify the
`gdalraster` engine. This is the fastest engine for computing large VRTs As it
parallises downloads and processing across bands and also across raster rows
using the nsplits argument. At the start of this workflow we set 10 mirai 
daemons. Because these are already set, they will be used as "outer" daemons
processing across bands - each of these daemons will then spawn 2 "inner"
daemons to process the rows of each band. This means that we will have 20
parallel processes running at once.

```{r hls-compute}
outfile <- tempfile(fileext = ".tif")
hls_composite <- vrt_compute(hls_stack, outfile, engine = "gdalraster", nsplits = 2)
```

Now let's take a look at a false-colour composite!

```{r hls-plot, fig.width=10, fig.height=8, fig.cap= ""}
plot_raster_src(
  hls_composite,
  bands = c(9, 3, 2),
  minmax_pct_cut = c(25, 97)
)
```

And all the other bands too:

```{r hls-plot-bands, fig.width=10, fig.height=8, fig.cap= ""}
par(mfrow = c(5, 3), mar = c(0, 0, 1, 0))
purrr::walk(1:15, function(i) {
  plot_raster_src(
    hls_composite,
    bands = i,
    pal = hcl.colors(256, "Rocket"),
    legend = FALSE,
    axes = FALSE
  )
})
```

#### Note.

This vignette is a work in progress and will be updated as the package matures.
Principally, the major goal is to use the geometric median for compositing.